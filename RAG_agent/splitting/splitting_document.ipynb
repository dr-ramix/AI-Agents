{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a201524d",
   "metadata": {},
   "source": [
    "## Splitting Text and Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e8584",
   "metadata": {},
   "source": [
    "### Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83d08153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#Document Loader:\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "#Text Splitters:\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "#Token Splitter:\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "#Markdown Splitter with structure\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ea3aa",
   "metadata": {},
   "source": [
    "### API-KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce828b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834d435",
   "metadata": {},
   "source": [
    "chunk_size: clarify the size of each split.\n",
    "\n",
    "\n",
    "chunk_overlap: how much can 2 neighbor chunk overlap with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86fdf368",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "824f7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "\n",
    "character_splitter = CharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5bb0d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f68b1efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd6712a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa599dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"abcdefghijklmnopqrstuvwxyzggjsitbcmsp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5fb4a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzggjsitbcmsp']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5fe58573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyzggjsitbcmsp']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b20c0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3024a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3c34ae93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cad83dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_splitter = CharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap,\n",
    "    separator= ' '\n",
    ")\n",
    "character_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "420c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nqs_text = \"\"\"\"\n",
    "NQS treat a wavefunction like a neural net: \\n\n",
    "instead of enumerating amplitudes for every spin configuration,\n",
    " you parameterize them with network weights, \n",
    " usually Restricted Boltzmann Machines or modern autoregressive nets.\n",
    " \\n\\nTraining becomes a variational Monte Carlo loop—sample configurations, estimate gradients of the energy with \n",
    " respect to the weights, nudge the model, repeat.\\n\\n\n",
    " This lets you capture entanglement patterns that are awkward for product \n",
    " states while keeping a compact parameter set.\n",
    " \\n\\nPeople prototype with small spin chains to benchmark\n",
    "   against exact diagonalization, then scale to frustrated lattices or fermionic encodings.\n",
    "   \\n\\nThe catch \n",
    "   is optimization; the landscape is gnarly, so tricks like natural gradient updates, symmetry constraints, \n",
    "   or hybridizing with tensor-network priors are common.\n",
    "   \\n\\nWhen it works, you essentially have a \n",
    "   flexible ansatz that can interpolate between mean-field intuition and highly correlated phases, and\n",
    "     it plays nicely with quantum-inspired algorithms—feeding its samples into quantum hardware or using it \n",
    "     to post-process noisy outputs.\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40649777",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 450,\n",
    "    chunk_overlap = 0,\n",
    "    separator= ' '\n",
    ")\n",
    "\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 450,\n",
    "    chunk_overlap = 0,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c0902814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\\nNQS treat a wavefunction like a neural net: \\n\\ninstead of enumerating amplitudes for every spin configuration,\\n you parameterize them with network weights, \\n usually Restricted Boltzmann Machines or modern autoregressive nets.\\n \\n\\nTraining becomes a variational Monte Carlo loop—sample configurations, estimate gradients of the energy with \\n respect to the weights, nudge the model, repeat.\\n\\n\\n This lets you capture entanglement patterns that are',\n",
       " 'awkward for product \\n states while keeping a compact parameter set.\\n \\n\\nPeople prototype with small spin chains to benchmark\\n against exact diagonalization, then scale to frustrated lattices or fermionic encodings.\\n \\n\\nThe catch \\n is optimization; the landscape is gnarly, so tricks like natural gradient updates, symmetry constraints, \\n or hybridizing with tensor-network priors are common.\\n \\n\\nWhen it works, you essentially have a \\n flexible ansatz',\n",
       " 'that can interpolate between mean-field intuition and highly correlated phases, and\\n it plays nicely with quantum-inspired algorithms—feeding its samples into quantum hardware or using it \\n to post-process noisy outputs.']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_splitter.split_text(nqs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f7085322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\\nNQS treat a wavefunction like a neural net: \\n\\ninstead of enumerating amplitudes for every spin configuration,\\n you parameterize them with network weights, \\n usually Restricted Boltzmann Machines or modern autoregressive nets.\\n \\n\\nTraining becomes a variational Monte Carlo loop—sample configurations, estimate gradients of the energy with \\n respect to the weights, nudge the model, repeat.',\n",
       " 'This lets you capture entanglement patterns that are awkward for product \\n states while keeping a compact parameter set.\\n \\n\\nPeople prototype with small spin chains to benchmark\\n   against exact diagonalization, then scale to frustrated lattices or fermionic encodings.',\n",
       " 'The catch \\n   is optimization; the landscape is gnarly, so tricks like natural gradient updates, symmetry constraints, \\n   or hybridizing with tensor-network priors are common.',\n",
       " 'When it works, you essentially have a \\n   flexible ansatz that can interpolate between mean-field intuition and highly correlated phases, and\\n     it plays nicely with quantum-inspired algorithms—feeding its samples into quantum hardware or using it \\n     to post-process noisy outputs.']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter.split_text(nqs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a0a1660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/33/28753zc950g7jnqk3b6ljhdr0000gn/T/ipykernel_11931/1880524880.py:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  separators = [\"\\n\\n\", \"\\n\", \"(?<=\\.)\" ,\" \", \"\"]\n"
     ]
    }
   ],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 450,\n",
    "    chunk_overlap = 0,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \"(?<=\\.)\" ,\" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8de5111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\\nNQS treat a wavefunction like a neural net: \\n\\ninstead of enumerating amplitudes for every spin configuration,\\n you parameterize them with network weights, \\n usually Restricted Boltzmann Machines or modern autoregressive nets.\\n \\n\\nTraining becomes a variational Monte Carlo loop—sample configurations, estimate gradients of the energy with \\n respect to the weights, nudge the model, repeat.',\n",
       " 'This lets you capture entanglement patterns that are awkward for product \\n states while keeping a compact parameter set.\\n \\n\\nPeople prototype with small spin chains to benchmark\\n   against exact diagonalization, then scale to frustrated lattices or fermionic encodings.',\n",
       " 'The catch \\n   is optimization; the landscape is gnarly, so tricks like natural gradient updates, symmetry constraints, \\n   or hybridizing with tensor-network priors are common.',\n",
       " 'When it works, you essentially have a \\n   flexible ansatz that can interpolate between mean-field intuition and highly correlated phases, and\\n     it plays nicely with quantum-inspired algorithms—feeding its samples into quantum hardware or using it \\n     to post-process noisy outputs.']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter.split_text(nqs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "11b86de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./docs/pdfs/G-CNN.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c76b33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size= 1000,\n",
    "    chunk_overlap= 150,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "55313ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c0a973df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac6c4e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.14', 'creator': 'TeX', 'creationdate': '2016-05-27T01:32:03+02:00', 'moddate': '2016-05-27T01:32:03+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1', 'source': './docs/pdfs/G-CNN.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}, page_content='Group Equivariant Convolutional Networks\\nTaco S. Cohen T.S.COHEN @UVA.NL\\nUniversity of Amsterdam\\nMax Welling M.WELLING @UVA.NL\\nUniversity of Amsterdam\\nUniversity of California Irvine\\nCanadian Institute for Advanced Research\\nAbstract\\nWe introduce Group equivariant Convolutional\\nNeural Networks (G-CNNs), a natural general-\\nization of convolutional neural networks that re-\\nduces sample complexity by exploiting symme-\\ntries. G-CNNs use G-convolutions, a new type of\\nlayer that enjoys a substantially higher degree of\\nweight sharing than regular convolution layers.\\nG-convolutions increase the expressive capacity\\nof the network without increasing the number of\\nparameters. Group convolution layers are easy\\nto use and can be implemented with negligible\\ncomputational overhead for discrete groups gen-\\nerated by translations, reﬂections and rotations.\\nG-CNNs achieve state of the art results on CI-\\nFAR10 and rotated MNIST.\\n1. Introduction\\nDeep convolutional neural networks (CNNs, convnets)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.14', 'creator': 'TeX', 'creationdate': '2016-05-27T01:32:03+02:00', 'moddate': '2016-05-27T01:32:03+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1', 'source': './docs/pdfs/G-CNN.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}, page_content='G-CNNs achieve state of the art results on CI-\\nFAR10 and rotated MNIST.\\n1. Introduction\\nDeep convolutional neural networks (CNNs, convnets)\\nhave proven to be very powerful models of sensory data\\nsuch as images, video, and audio. Although a strong the-\\nory of neural network design is currently lacking, a large\\namount of empirical evidence supports the notion that both\\nconvolutional weight sharing and depth (among other fac-\\ntors) are important for good predictive performance.\\nConvolutional weight sharing is effective because there is\\na translation symmetry in most perception tasks: the la-\\nbel function and data distribution are both approximately\\ninvariant to shifts. By using the same weights to analyze\\nor model each part of the image, a convolution layer uses\\nfar fewer parameters than a fully connected one, while pre-\\nserving the capacity to learn many useful transformations.\\nProceedings of the 33 rd International Conference on Machine'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.14', 'creator': 'TeX', 'creationdate': '2016-05-27T01:32:03+02:00', 'moddate': '2016-05-27T01:32:03+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1', 'source': './docs/pdfs/G-CNN.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}, page_content='serving the capacity to learn many useful transformations.\\nProceedings of the 33 rd International Conference on Machine\\nLearning, New York, NY , USA, 2016. JMLR: W&CP volume\\n48. Copyright 2016 by the author(s).\\nConvolution layers can be used effectively in a deep net-\\nwork because all the layers in such a network are trans-\\nlation equivariant : shifting the image and then feeding\\nit through a number of layers is the same as feeding the\\noriginal image through the same layers and then shifting\\nthe resulting feature maps (at least up to edge-effects). In\\nother words, the symmetry (translation) is preserved by\\neach layer, which makes it possible to exploit it not just\\nin the ﬁrst, but also in higher layers of the network.\\nIn this paper we show how convolutional networks can be\\ngeneralized to exploit larger groups of symmetries, includ-\\ning rotations and reﬂections. The notion of equivariance is\\nkey to this generalization, so in section 2 we will discuss'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.14', 'creator': 'TeX', 'creationdate': '2016-05-27T01:32:03+02:00', 'moddate': '2016-05-27T01:32:03+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1', 'source': './docs/pdfs/G-CNN.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}, page_content='ing rotations and reﬂections. The notion of equivariance is\\nkey to this generalization, so in section 2 we will discuss\\nthis concept and its role in deep representation learning.\\nAfter discussing related work in section 3, we recall a num-\\nber of mathematical concepts in section 4 that allow us to\\ndeﬁne and analyze the G-convolution in a generic manner.\\nIn section 5, we analyze the equivariance properties of stan-\\ndard CNNs, and show that they are equivariant to trans-\\nlations but may fail to equivary with more general trans-\\nformations. Using the mathematical framework from sec-\\ntion 4, we can deﬁne G-CNNs (section 6) by analogy to\\nstandard CNNs (the latter being the G-CNN for the transla-\\ntion group). We show that G-convolutions, as well as var-\\nious kinds of layers used in modern CNNs, such as pool-\\ning, arbitrary pointwise nonlinearities, batch normalization\\nand residual blocks are all equivariant, and thus compatible\\nwith G-CNNs. In section 7 we provide concrete implemen-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.14', 'creator': 'TeX', 'creationdate': '2016-05-27T01:32:03+02:00', 'moddate': '2016-05-27T01:32:03+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1', 'source': './docs/pdfs/G-CNN.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}, page_content='and residual blocks are all equivariant, and thus compatible\\nwith G-CNNs. In section 7 we provide concrete implemen-\\ntation details for group convolutions.\\nIn section 8 we report experimental results on MNIST-rot\\nand CIFAR10, where G-CNNs achieve state of the art re-\\nsults (2.28% error on MNIST-rot, and 4.19% resp. 6.46%\\non augmented and plain CIFAR10). We show that replac-\\ning planar convolutions with G-convolutions consistently\\nimproves results without additional tuning. In section 9 we\\nprovide a discussion of these results and consider several\\nextensions of the method, before concluding in section 10.')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac343a",
   "metadata": {},
   "source": [
    "### TOKEN SPLITTER\n",
    "##### Tokens are usually 4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "28ba8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a0cf7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"foo bar bazzyfoo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5643846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "251c716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ed083f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.14', 'creator': 'TeX', 'creationdate': '2016-05-27T01:32:03+02:00', 'moddate': '2016-05-27T01:32:03+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1', 'source': './docs/pdfs/G-CNN.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}, page_content='Group Equivariant Convolutional Networks\\nTaco S. Cohen T.S.COHEN @UVA.NL\\nUniversity of Amsterdam\\nMax Welling M.WELLING @UVA.NL\\nUniversity of Amsterdam\\nUniversity of California Irvine\\nCanadian Institute for Advanced Research\\nAbstract\\nWe introduce Group equivariant Convolutional\\nNeural Networks (G-CNNs), a natural general-\\nization of convolutional neural networks that re-\\nduces sample complexity by exploiting symme-\\ntries. G-CNNs use G-convolutions, a new type of\\nlayer that enjoys a substantially higher degree of\\nweight sharing than regular convolution layers.\\nG-convolutions increase the expressive capacity\\nof the network without increasing the number of\\nparameters. Group convolution layers are easy\\nto use and can be implemented with negligible\\ncomputational overhead for discrete groups gen-\\nerated by translations, reﬂections and rotations.\\nG-CNNs achieve state of the art results on CI-\\nFAR10 and rotated MNIST.\\n1. Introduction\\nDeep convolutional neural networks (CNNs, convnets)')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30b9271d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.14',\n",
       " 'creator': 'TeX',\n",
       " 'creationdate': '2016-05-27T01:32:03+02:00',\n",
       " 'moddate': '2016-05-27T01:32:03+02:00',\n",
       " 'trapped': '/False',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1',\n",
       " 'source': './docs/pdfs/G-CNN.pdf',\n",
       " 'total_pages': 10,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05421ed3",
   "metadata": {},
   "source": [
    "### Markdown-base splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "322f89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "99df262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", 'Header 1'),\n",
    "    (\"##\", 'Header 2'),\n",
    "    (\"###\", 'Header 3')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d3ffe31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ad5a4e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "813a7f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='Hi this is Lance')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
