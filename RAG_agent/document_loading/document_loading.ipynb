{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d0a206",
   "metadata": {},
   "source": [
    "## Document Loading Process for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988ed27",
   "metadata": {},
   "source": [
    "### Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c9db8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#PDF\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "#YouTube\n",
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers.audio import OpenAIWhisperParser\n",
    "\n",
    "#WEB \n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19ebcf",
   "metadata": {},
   "source": [
    "### API-KEY for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d294bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77056f",
   "metadata": {},
   "source": [
    "### Loading PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0dfed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./docs/pdf_files/G-CNN.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215c3c3",
   "metadata": {},
   "source": [
    "To check number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e98561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cda978",
   "metadata": {},
   "source": [
    "splitting the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceca9fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Group Equivariant Convolutional Networks\n",
      "Taco S. Cohen T.S.COHEN @UVA.NL\n",
      "University of Amsterdam\n",
      "Max Welling M.WELLING @UVA.NL\n",
      "University of Amsterdam\n",
      "University of California Irvine\n",
      "Canadian Institute for Advanced Research\n",
      "Abstract\n",
      "We introduce Group equivariant Convolutional\n",
      "Neural Networks (G-CNNs), a natural general-\n",
      "ization of convolutional neural networks that re-\n",
      "duces sample complexity by exploiting symme-\n",
      "tries. G-CNNs use G-convolutions, a new type of\n",
      "layer that enjoys a substantially higher degree of\n",
      "weight sharing than regular convolution layers.\n",
      "G-convolutions increase the expressive capacity\n",
      "of the network without increasing the number of\n",
      "parameters. Group convolution layers are easy\n",
      "to use and can be implemented with negligible\n",
      "computational overhead for discrete groups gen-\n",
      "erated by translations, reﬂections and rotations.\n",
      "G-CNNs achieve state of the art results on CI-\n",
      "FAR10 and rotated MNIST.\n",
      "1. Introduction\n",
      "Deep convolutional neural networks (CNNs, convnets)\n",
      "have proven to be very powerful models of sensory data\n",
      "such as images, video, and audio. Although a strong the-\n",
      "ory of neural network design is currently lacking, a large\n",
      "amount of empirical evidence supports the notion that both\n",
      "convolutional weight sharing and depth (among other fac-\n",
      "tors) are important for good predictive performance.\n",
      "Convolutional weight sharing is effective because there is\n",
      "a translation symmetry in most perception tasks: the la-\n",
      "bel function and data distribution are both approximately\n",
      "invariant to shifts. By using the same weights to analyze\n",
      "or model each part of the image, a convolution layer uses\n",
      "far fewer parameters than a fully connected one, while pre-\n",
      "serving the capacity to learn many useful transformations.\n",
      "Proceedings of the 33 rd International Conference on Machine\n",
      "Learning, New York, NY , USA, 2016. JMLR: W&CP volume\n",
      "48. Copyright 2016 by the author(s).\n",
      "Convolution layers can be used effectively in a deep net-\n",
      "work because all the layers in such a network are trans-\n",
      "lation equivariant : shifting the image and then feeding\n",
      "it through a number of layers is the same as feeding the\n",
      "original image through the same layers and then shifting\n",
      "the resulting feature maps (at least up to edge-effects). In\n",
      "other words, the symmetry (translation) is preserved by\n",
      "each layer, which makes it possible to exploit it not just\n",
      "in the ﬁrst, but also in higher layers of the network.\n",
      "In this paper we show how convolutional networks can be\n",
      "generalized to exploit larger groups of symmetries, includ-\n",
      "ing rotations and reﬂections. The notion of equivariance is\n",
      "key to this generalization, so in section 2 we will discuss\n",
      "this concept and its role in deep representation learning.\n",
      "After discussing related work in section 3, we recall a num-\n",
      "ber of mathematical concepts in section 4 that allow us to\n",
      "deﬁne and analyze the G-convolution in a generic manner.\n",
      "In section 5, we analyze the equivariance properties of stan-\n",
      "dard CNNs, and show that they are equivariant to trans-\n",
      "lations but may fail to equivary with more general trans-\n",
      "formations. Using the mathematical framework from sec-\n",
      "tion 4, we can deﬁne G-CNNs (section 6) by analogy to\n",
      "standard CNNs (the latter being the G-CNN for the transla-\n",
      "tion group). We show that G-convolutions, as well as var-\n",
      "ious kinds of layers used in modern CNNs, such as pool-\n",
      "ing, arbitrary pointwise nonlinearities, batch normalization\n",
      "and residual blocks are all equivariant, and thus compatible\n",
      "with G-CNNs. In section 7 we provide concrete implemen-\n",
      "tation details for group convolutions.\n",
      "In section 8 we report experimental results on MNIST-rot\n",
      "and CIFAR10, where G-CNNs achieve state of the art re-\n",
      "sults (2.28% error on MNIST-rot, and 4.19% resp. 6.46%\n",
      "on augmented and plain CIFAR10). We show that replac-\n",
      "ing planar convolutions with G-convolutions consistently\n",
      "improves results without additional tuning. In section 9 we\n",
      "provide a discussion of these results and consider several\n",
      "extensions of the method, before concluding in section 10.' metadata={'producer': 'pdfTeX-1.40.14', 'creator': 'TeX', 'creationdate': '2016-05-27T01:32:03+02:00', 'moddate': '2016-05-27T01:32:03+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1', 'source': './docs/pdf_files/G-CNN.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "page_01 = pages[0]\n",
    "print(page_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c607be6",
   "metadata": {},
   "source": [
    "Accessing to page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "855f0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract\n",
      "We introduce Group equivariant Convolutional\n",
      "Neural Networks (G-CNNs), a natural general-\n",
      "ization of convolutional neural networks that re-\n",
      "duces sample complexity by exploiting symme-\n",
      "tries. G-CNNs use G-convolutions, a new type of\n",
      "layer that enjoys a substantially higher degree of\n",
      "weight sharing than regular convolution layers.\n",
      "G-convolutions increase the expressive capacity\n",
      "of the network without increasing the number of\n",
      "parameters. Group convolution layers are easy\n",
      "to use and can be implemented with negligible\n",
      "computational overhead for discrete groups gen-\n",
      "erated by translations, reﬂections and rotations.\n",
      "G-CNNs achieve state of the art results on CI-\n",
      "FAR10 and rotated MNIST.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abstract = page_01.page_content[223:923]\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac55c0",
   "metadata": {},
   "source": [
    "Accessing Meta Data of each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cae453b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.14',\n",
       " 'creator': 'TeX',\n",
       " 'creationdate': '2016-05-27T01:32:03+02:00',\n",
       " 'moddate': '2016-05-27T01:32:03+02:00',\n",
       " 'trapped': '/False',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013/Debian) kpathsea version 6.1.1',\n",
       " 'source': './docs/pdf_files/G-CNN.pdf',\n",
       " 'total_pages': 10,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_01.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f39682",
   "metadata": {},
   "source": [
    "### Loading from YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "186907dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jwnez8HdN7E&t=10s\n",
      "[youtube] jwnez8HdN7E: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] jwnez8HdN7E: Downloading android sdkless player API JSON\n",
      "[youtube] jwnez8HdN7E: Downloading web safari player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] jwnez8HdN7E: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] jwnez8HdN7E: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] jwnez8HdN7E: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] jwnez8HdN7E: Downloading 1 format(s): 140-5\n",
      "[download] docs/youtube//Microsoft’s new chip looks like science fiction….m4a has already been downloaded\n",
      "[download] 100% of    4.00MiB\n",
      "[ExtractAudio] Not converting audio docs/youtube//Microsoft’s new chip looks like science fiction….m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n",
      "Out of nowhere, Microsoft just announced an impossible new quantum computing chip named Mirona 1. But it's not your average quantum chip. They claim to have created an entirely new state of matter. So now we have solid, liquid, gas, plasma, and the new kid on the block, the topo-computer, or topological supercomputer. It is entirely a new state of matter. If it turns out not to be your typical Microsoft BS, and that's a big if, it could be a breakthrough on par with the transistor. The humble transistor allowed computers to scale up to millions of bits, and the topo-computer could be the technology that allows us to scale up to millions of qubits. Without exaggeration, that would make computers billions of times faster than current tech, allowing us to do incredible things like develop new medicines, assimilate entire worlds of AI girlfriends, and run Microsoft Windows updates in seconds instead of hours. In today's video, we'll look at the crazy science behind Microsoft's Mirona 1 chi\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=jwnez8HdN7E&t=10s\"\n",
    "save_dir = \"docs/youtube/\"\n",
    "\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "video = loader.load()\n",
    "print(video[0].page_content[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032bcc3b",
   "metadata": {},
   "source": [
    "### Loading base on a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efdbafdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bachelor Elektrotechnik und Informationstechnik - TUM - TUM School of Computation, Information and Technology\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tZum Inhalt springen\n",
      "\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "de\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "en\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Google Suche\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menü\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            TUM School of Computation, Information and Technology\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "                            Technische Universität München\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                        Startseite\n",
      "                                    \n",
      "\n",
      "\n",
      "\n",
      "                                        Studium\n",
      "                                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            Vor dem Studium\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            Schulprogramme\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            Schnupperstudium Elektrotechnik Informationstechnik\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "                            Schnupperstudium Informatik\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "                       \n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://www.cit.tum.de/cit/studium/studiengaenge/bachelor-elektrotechnik-informationstechnik/\")\n",
    "docs_url = loader.load()\n",
    "\n",
    "print(docs_url[0].page_content[0:1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
